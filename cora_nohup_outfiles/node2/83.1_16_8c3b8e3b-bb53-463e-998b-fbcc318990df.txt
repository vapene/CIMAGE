logs of node classification loss:
non_zero_list: (4.5, [4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 7, 7, 7, 7, 7, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2])


{'dataset': 'Cora', 'device': 0, 'encoder_hidden': 512, 'encoder_out': 512, 'encoder_layers': 1, 'encoder_dropout': 0.85, 'decoder_hidden': 32, 'decoder_layers': 2, 'decoder_dropout': 0.31, 'ch_decoder_layers': 3, 'ch_decoder_dropout': 0.54, 'cluster_emb': 0.995, 'trace_reg': 0.1, 'nb_size': 50, 'ncaps': 16, 'nlayer': 5, 'max_iter': 10, 'hsic_lamb': 0.001225, 'link_lr_max': 0.1, 'link_lr_min': 0.005, 'node_lr_max': 0.01, 'node_lr_min': 0.01, 'grad_norm': 1.0, 'recon_alpha': 0.00989, 'batch_size': 65536, 'l2_normalize': True, 'alpha_l': 1, 'weight_decay': 5e-05, 'nodeclas_weight_decay': 0.0023, 'epochs': 200, 'eval_period': 1, 'save_path': 'model_nodeclas.pth', 'trial': 10, 'mask': 'Path', 'knn_nb': 50, 'original_lamb': 0.8, 'new_lamb': 1.0, 'patience': 70, 'bn': True}
seed 0 runs 10
AUC_val: [0.9683504423376745]
AP_val: [0.9725878799325225]
AUC_test: [0.9725021324581822]
AP_test: [0.9785366528599655]
val: [0.8119999766349792]
test: [0.8309999704360962]
96.84±0.00
97.26±0.00
97.25±0.00
97.85±0.00
81.20±0.00
83.10±0.00